{
	"_name_or_path": "./",
	"activation_dropout": 0.0,
	"activation_function": "gelu",
	"architectures": ["EmmaForConditionalGeneration"],
	"attention_dropout": 0.0,
	"attention_window": [128, 128, 128],
	"bos_token_id": 0,
	"classif_dropout": 0.0,
	"classifier_dropout": 0.0,
	"d_model": 368,
	"decoder_attention_heads": 8,
	"decoder_ffn_dim": 512,
	"decoder_layerdrop": 0.0,
	"decoder_layers": 3,
	"decoder_start_token_id": 2,
	"dropout": 0.1,
	"encoder_attention_heads": 8,
	"encoder_ffn_dim": 512,
	"encoder_layerdrop": 0.0,
	"encoder_layers": 3,
	"eos_token_id": 2,
	"gradient_checkpointing": false,
	"id2label": {
		"0": "LABEL_0",
		"1": "LABEL_1",
		"2": "LABEL_2"
	},
	"init_std": 0.02,
	"is_encoder_decoder": true,
	"label2id": {
		"LABEL_0": 0,
		"LABEL_1": 1,
		"LABEL_2": 2
	},
	"max_decoder_position_embeddings": 512,
	"max_encoder_position_embeddings": 16384,
	"max_frame_embeddings": 256,
	"model_type": "emma",
	"num_hidden_layers": 3,
	"pad_token_id": 1,
	"use_cache": true,
	"vocab_size": 10259,
	"scene_features_dim": 1024,
	"object_features_dim": 2048,
	"image_coordinates_dim": 4,
	"use_encoder_global_positional_embeddings": false
}
